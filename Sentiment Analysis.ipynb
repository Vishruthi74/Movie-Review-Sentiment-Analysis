{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('movie_reviews.csv')\n",
    "\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_html_tag(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_accents(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding Contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\"ain't\": \"is not\",\n",
    "                   \"aren't\": \"are not\",\n",
    "                   \"can't\": \"cannot\",\n",
    "                   \"can't've\": \"cannot have\",\n",
    "                   \"'cause\": \"because\",\n",
    "                   \"could've\": \"could have\",\n",
    "                   \"couldn't\": \"could not\",\n",
    "                   \"couldn't've\": \"could not have\",\n",
    "                   \"didn't\": \"did not\",\n",
    "                   \"doesn't\": \"does not\",\n",
    "                   \"don't\": \"do not\",\n",
    "                   \"hadn't\": \"had not\",\n",
    "                   \"hadn't've\": \"had not have\",\n",
    "                   \"hasn't\": \"has not\",\n",
    "                   \"haven't\": \"have not\",\n",
    "                   \"he'd\": \"he would\",\n",
    "                   \"he'd've\": \"he would have\",\n",
    "                   \"he'll\": \"he will\",\n",
    "                   \"he'll've\": \"he will have\",\n",
    "                   \"he's\": \"he is\",\n",
    "                   \"how'd\": \"how did\",\n",
    "                   \"how'd'y\": \"how do you\",\n",
    "                   \"how'll\": \"how will\",\n",
    "                   \"how's\": \"how is\",\n",
    "                   \"I'd\": \"I would\",\n",
    "                   \"I'd've\": \"I would have\",\n",
    "                   \"I'll\": \"I will\",\n",
    "                   \"I'll've\": \"I will have\",\n",
    "                   \"I'm\": \"I am\",\n",
    "                   \"I've\": \"I have\",\n",
    "                   \"i'd\": \"i would\",\n",
    "                   \"i'd've\": \"i would have\",\n",
    "                   \"i'll\": \"i will\",\n",
    "                   \"i'll've\": \"i will have\",\n",
    "                   \"i'm\": \"i am\",\n",
    "                   \"i've\": \"i have\",\n",
    "                   \"isn't\": \"is not\",\n",
    "                   \"it'd\": \"it would\",\n",
    "                   \"it'd've\": \"it would have\",\n",
    "                   \"it'll\": \"it will\",\n",
    "                   \"it'll've\": \"it will have\",\n",
    "                   \"it's\": \"it is\",\n",
    "                   \"let's\": \"let us\",\n",
    "                   \"ma'am\": \"madam\",\n",
    "                   \"mayn't\": \"may not\",\n",
    "                   \"might've\": \"might have\",\n",
    "                   \"mightn't\": \"might not\",\n",
    "                   \"mightn't've\": \"might not have\",\n",
    "                   \"must've\": \"must have\",\n",
    "                   \"mustn't\": \"must not\",\n",
    "                   \"mustn't've\": \"must not have\",\n",
    "                   \"needn't\": \"need not\",\n",
    "                   \"needn't've\": \"need not have\",\n",
    "                   \"o'clock\": \"of the clock\",\n",
    "                   \"oughtn't\": \"ought not\",\n",
    "                   \"oughtn't've\": \"ought not have\",\n",
    "                   \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\",\n",
    "                   \"shan't've\": \"shall not have\",\n",
    "                   \"she'd\": \"she would\",\n",
    "                   \"she'd've\": \"she would have\",\n",
    "                   \"she'll\": \"she will\",\n",
    "                   \"she'll've\": \"she will have\",\n",
    "                   \"she's\": \"she is\",\n",
    "                   \"should've\": \"should have\",\n",
    "                   \"shouldn't\": \"should not\",\n",
    "                   \"shouldn't've\": \"should not have\",\n",
    "                   \"so've\": \"so have\",\n",
    "                   \"so's\": \"so as\",\n",
    "                   \"that'd\": \"that would\",\n",
    "                   \"that'd've\": \"that would have\",\n",
    "                   \"that's\": \"that is\",\n",
    "                   \"there'd\": \"there would\",\n",
    "                   \"there'd've\": \"there would have\",\n",
    "                   \"there's\": \"there is\",\n",
    "                   \"they'd\": \"they would\",\n",
    "                   \"they'd've\": \"they would have\",\n",
    "                   \"they'll\": \"they will\",\n",
    "                   \"they'll've\": \"they will have\",\n",
    "                   \"they're\": \"they are\",\n",
    "                   \"they've\": \"they have\",\"to've\": \"to have\",\n",
    "                   \"wasn't\": \"was not\",\n",
    "                   \"we'd\": \"we would\",\n",
    "                   \"we'd've\": \"we would have\",\n",
    "                   \"we'll\": \"we will\",\n",
    "                   \"we'll've\": \"we will have\",\n",
    "                   \"we're\": \"we are\",\n",
    "                   \"we've\": \"we have\",\n",
    "                   \"weren't\": \"were not\",\n",
    "                   \"what'll\": \"what will\",\n",
    "                   \"what'll've\": \"what will have\",\n",
    "                   \"what're\": \"what are\",\n",
    "                   \"what's\": \"what is\",\n",
    "                   \"what've\": \"what have\",\n",
    "                   \"when's\": \"when is\",\n",
    "                   \"when've\": \"when have\",\n",
    "                   \"where'd\": \"where did\",\n",
    "                   \"where's\": \"where is\",\n",
    "                   \"where've\": \"where have\",\n",
    "                   \"who'll\": \"who will\",\n",
    "                   \"who'll've\": \"who will have\",\n",
    "                   \"who's\": \"who is\",\n",
    "                   \"who've\": \"who have\",\n",
    "                   \"why's\": \"why is\",\n",
    "                   \"why've\": \"why have\",\n",
    "                   \"will've\": \"will have\",\n",
    "                   \"won't\": \"will not\",\n",
    "                   \"won't've\": \"will not have\",\n",
    "                   \"would've\": \"would have\",\n",
    "                   \"wouldn't\": \"would not\",\n",
    "                   \"wouldn't've\": \"would not have\",\n",
    "                   \"y'all\": \"you all\",\n",
    "                   \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\n",
    "                   \"y'all're\": \"you all are\",\n",
    "                   \"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\",\n",
    "                   \"you'd've\": \"you would have\",\n",
    "                   \"you'll\": \"you will\",\n",
    "                   \"you'll've\": \"you will have\",\n",
    "                   \"you're\": \"you are\",\n",
    "                   \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  It is an amazing language which can be used for Scripting'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(\"  It's an amazing language which can be used for Scripting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_special_characters(text):\n",
    "    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    tokens = nltk.word_tokenize (text)\n",
    "    text =' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_stopwords(text, is_lower_case=False):\n",
    "    tokens = nltk.word_tokenize (text)\n",
    "    #tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaned Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text,strip_html=True, expand_contraction=True,\n",
    "               accent_remove=True, text_lower_case=True,text_lemmatize=True, \n",
    "               special_char_remove=True, stopword_remove=True):\n",
    "    \n",
    "    processed_text=[]\n",
    "    for doc in text:\n",
    "        \n",
    "        #HTML tah striping\n",
    "        if strip_html:\n",
    "            doc=strip_html_tag(doc)\n",
    "        \n",
    "        ## remove accented characters\n",
    "        if accent_remove:\n",
    "            doc = strip_accents(doc)\n",
    "            \n",
    "        # expand contractions    \n",
    "        if expand_contraction:\n",
    "            doc = expand_contractions(doc)\n",
    "            \n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "            \n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        \n",
    "        # insert spaces between special characters to isolate them    \n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "        \n",
    "        # lemmatizing text\n",
    "        if text_lemmatize:\n",
    "            doc = lemmatize_text(doc)\n",
    "        \n",
    "        # remove special characters    \n",
    "        if special_char_remove:\n",
    "            doc = strip_special_characters(doc)  \n",
    "        \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        \n",
    "        # remove stopwords\n",
    "        if stopword_remove:\n",
    "            doc = strip_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        processed_text.append(doc)\n",
    "        \n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentiment Analysis with AFINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afn = Afinn(emoticons=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id= [4726,12103,25726,49255]\n",
    "sample_reviews= reviews[sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What the (beep) is going wrong with Disney the last years? Are there totally run out of good ideas? Where is the magic? Where are the good animators, the good songwriters, the good directors, the good... Okay, i know, Walt himself and the famous \"nine old man\" can\\'t come back. But is this a reason to crank out countless of those cheap sequels and slowly but surely destroying the ideals of Walt Disney? I never rent or bought a Disney-sequel of what movie however. Because i had read much enough about its (absence of) quality. But \"Atlantis: Milo\\'s Return\" was aired today on TV in Germany and so i watch it. It confirmed my doubts about sequels. It was absolutely boring. Flaw animation, primitive color-rotation, simple characters, some unsuccessful tries to simulate the famous Multiplane-Camera with CGI, mediocre music and a patchwork of different, simple stories. It looks absolutely not like Disney! Not like Disney i know! It looks like one of the countless, cheap and simple animation-series like \"DragonballZ\", \"Beyblade\" etc. that aired every day on TV for children.<br /><br />My first reaction after showing this crap, was to load \"Bambi\" in my DVD-Player, to see Disney\\'s immortal magic, depth, spirit and charm again, to see Disney on its climax again, to see the awesome art of handmade animation again. \"Bambi\" was the first (and until today the only) movie that i give 10 out of 10 stars. But \"Atlantis: Milo\\'s Return\"? No magic, no depth, no charm, no spirit... It deserved only 3 out of 10!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_reviews[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_reviews=clean_text(sample_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beep going wrong disney last year totally run good idea magic good animator good songwriter good director good okay know walt famous `` nine old man not come back reason crank countless cheap sequel slowly surely destroying ideal walt disney never rent bought disneysequel movie however read much enough absence quality `` atlantis milo return wa aired today tv germany watch confirmed doubt sequel wa absolutely boring flaw animation primitive colorrotation simple character unsuccessful try simulate famous multiplanecamera cgi mediocre music patchwork different simple story look absolutely not like disney not like disney know look like one countless cheap simple animationseries like `` dragonballz `` beyblade etc aired every day tv child first reaction showing crap wa load `` bambi dvdplayer see disney immortal magic depth spirit charm see disney climax see awesome art handmade animation `` bambi wa first today movie give 10 10 star `` atlantis milo return no magic no depth no charm no spirit deserved 3 10'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_reviews[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: Utter dreck. I got to the 16 minute/27 second point, and gave up. I'd have given it a negative number review if that were possible (although 'pissible' is a more fitting word...). Unlike the sizzle you could see and practically feel between MacMurray and Stanwyck in the original, the chemistry between dumb ol' Dicky Crenna and whats-her-face here is just non-existent. The anklet becomes an unattractive chunky bracelet? There's no ciggy-lighting-by-fingertip? And I thought I'd be SICK when they have a mortified-looking (and rightly so, believe you me) Lee J. Cobb as Keyes practically burping/upchucking his way through the explanation of his \"Little Man\" to Mr. Garloupis. No offence to the non-sighted, but it looks as though a posse of blind men ran amuck with the set design of both the Dietrichson and Neff houses. The same goes for those horrid plaid pants that Phyllis wears. And crikey, how much $$ does Neff make, that he lives overlooking a huge marina? This, folks, again, all takes place in the first 16 and a half minutes. If you can get through more of it, you have a much stronger constitution than me, or you are a masochist. But please, take some Alka-Seltzer first, or you WILL develop a \"little man\" of your own that may never go away. Proceed with caution, obviously.\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment polarity: -13.0\n",
      "************************************************************************************************************************\n",
      "REVIEW: This must be the worst thriller I have seen in a long long time. The directing, the acting and the adaptation of the story leave what could probably have been a good plot into a meaningless waste of time. Within a few minutes of watching the film it was easy to figure out the whole plot and then there are more obvious clues very early on leaving no mystery. I guessed this within the first few minutes and I kept hoping I was wrong and much to my dismay I was not.<br /><br />The film starts off with two FBI agents who drive to a remote town to investigate a murderous spree which has left three witnesses, a young girl, a drug addict and a cop. They are interviewed under surveillance cameras separately and each tells their account of the day. Each has something to hide about themselves and the day unfolds as they tell their accounts. This part is probably the saving grace and if developed could have made this film better.<br /><br />Spoiler: The whole story ends in the FBI agents being the actual killers and the young girl is the only one who has figured this out and so left unhurt by them.<br /><br />Why do they go through the whole charade of interviewing three witnesses and bonding with the young girl if their idea had been to kill them in the first place? How did they get away with pretending to be FBI agents (when you discover that real FBI agents had been killed and their badges were found on them)? How did they know how to set up and use the surveillance cameras?<br /><br />Bill Pullman and Julia Ormond are so unconvincing from the beginning to the end. Maybe the idea is to develop their characters for the revelation at the end. Come on, they both look ridiculous, stupid and not sinister in the least. The character of the young girl is also wasted potential. There is no meaning to her actions and no meaning to whom she prefers to bond with in her ordeal. She does not appear distressed, but rather detached which again is not explained. <br /><br />Awful film on the whole.\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment polarity: -29.0\n",
      "************************************************************************************************************************\n",
      "REVIEW: What the (beep) is going wrong with Disney the last years? Are there totally run out of good ideas? Where is the magic? Where are the good animators, the good songwriters, the good directors, the good... Okay, i know, Walt himself and the famous \"nine old man\" can't come back. But is this a reason to crank out countless of those cheap sequels and slowly but surely destroying the ideals of Walt Disney? I never rent or bought a Disney-sequel of what movie however. Because i had read much enough about its (absence of) quality. But \"Atlantis: Milo's Return\" was aired today on TV in Germany and so i watch it. It confirmed my doubts about sequels. It was absolutely boring. Flaw animation, primitive color-rotation, simple characters, some unsuccessful tries to simulate the famous Multiplane-Camera with CGI, mediocre music and a patchwork of different, simple stories. It looks absolutely not like Disney! Not like Disney i know! It looks like one of the countless, cheap and simple animation-series like \"DragonballZ\", \"Beyblade\" etc. that aired every day on TV for children.<br /><br />My first reaction after showing this crap, was to load \"Bambi\" in my DVD-Player, to see Disney's immortal magic, depth, spirit and charm again, to see Disney on its climax again, to see the awesome art of handmade animation again. \"Bambi\" was the first (and until today the only) movie that i give 10 out of 10 stars. But \"Atlantis: Milo's Return\"? No magic, no depth, no charm, no spirit... It deserved only 3 out of 10!\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment polarity: 23.0\n",
      "************************************************************************************************************************\n",
      "REVIEW: Assassin Hauser's (John Cusak) mission is to whack a Mid-Eastern oil minister, whose name happens to be Omar Sharif (Neikov), in the country of Turaqistan which is run by American interests. Hauser poses as Trade Show producer to allow him to get to Omar.<br /><br />Sometimes a satire can be so overdone it becomes most annoying. Here it does too much: the government, politics, music, war, people not generally accepted by society, and did I mention \"war.\" And, that is what we have here - a most annoying movie that borders on a very bad nightmare brought to life. I am still asking myself why I continued with the DVD. Also, there are so many Cusak family members in this that John Cusak appears embarrassed by the family just being there, or is that just me?<br /><br />It used to be that a John Cusak movie, while a little offbeat, was, in the end, rather good. Not here. Believe that John Cusak had a hand in the writing and producing of this mess. Make of that what you will.<br /><br />There is too much going on in the movie accompanied by constant gun-fire, bombings, and shouting that you really cannot focus or was that the point? Probably. It just takes too long to set up the hit, which is largely forgotten until the last 15-minutes. In the meantime we have meaningless banter among all in the cast. And, chemistry between John Cusak and Marisa Tormei? I don't think so, but you know: the boy  girl thing ",
      "",
      "and they needed something to take up more time. <br /><br />Yes, for what they were supposed to be, (offbeat and annoying) the performances of Duff, and Kingsley were good. But, when I saw Dan Aykroyd's character, in the beginning of the show, sitting on a toilet taking a dump, I knew the rest of the show would go to the tank as well. I was not wrong. I am sure some will sing praises of this effort, but if a rose is still a rose by any other name so, too, is a mess",
      "",
      "",
      "",
      "",
      "<br /><br />I now remember why I continued with the DVD. I was hoping that the story would somehow level out and save itself. Never did.<br /><br />Violence: Yes. Sex: No. Nudity: No. Language: Yes.\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment polarity: -12.0\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(reviews[sample_id], sentiments[sample_id]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    print('Predicted Sentiment polarity:', afn.score(review))\n",
    "    print('*'*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment for Complete Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_polarity = [afn.score(review) for review in reviews]\n",
    "pred_sentiment = ['positive' if score >= 1.0 else 'negative' for score in sent_polarity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_metric(actual_sent, predicted_sent):\n",
    "    print(\"Accuracy:\", np.round(metrics.accuracy_score(actual_sent,predicted_sent),4))\n",
    "    print('Precision:', np.round(metrics.precision_score(actual_sent, predicted_sent, average='weighted'),4))\n",
    "    print('Recall:', np.round(metrics.recall_score(actual_sent,predicted_sent,average='weighted'),4))\n",
    "    print('F1 Score:', np.round( metrics.f1_score(actual_sent,predicted_sent,average='weighted'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_confusion_matrix(actual_sent, predicted_sent, classes=[1,0]):\n",
    "    \n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_true=actual_sent, y_pred=predicted_sent, labels=classes)\n",
    "    cm_frame = pd.DataFrame(data=cm, columns=pd.MultiIndex(levels=[['Predicted:'], classes], labels=level_labels),\n",
    "                            index=pd.MultiIndex(levels=[['Actual:'], classes], labels=level_labels)) \n",
    "    print(cm_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_classification_report(actual_sent, predicted_sent, classes=[1,0]):\n",
    "\n",
    "    report = metrics.classification_report(y_true=actual_sent,y_pred=predicted_sent, labels=classes) \n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_model_performance(actual_sent, predicted_sent, classes=[1,0]):\n",
    "    print('\\nPrediction Confusion Matrix:')\n",
    "    print('*'*50)\n",
    "    display_confusion_matrix(actual_sent=actual_sent, predicted_sent=predicted_sent,classes=classes)\n",
    "    print('\\nModel Classification report:')\n",
    "    print('*'*50)\n",
    "    display_classification_report(actual_sent=actual_sent, predicted_sent=predicted_sent,classes=classes)    \n",
    "    print('Model Performance metrics:')\n",
    "    print('*'*50)\n",
    "    display_metric(actual_sent=actual_sent, predicted_sent=predicted_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Confusion Matrix:\n",
      "**************************************************\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive      21147     3853\n",
      "        negative      10539    14461\n",
      "\n",
      "Model Classification report:\n",
      "**************************************************\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.67      0.85      0.75     25000\n",
      "   negative       0.79      0.58      0.67     25000\n",
      "\n",
      "avg / total       0.73      0.71      0.71     50000\n",
      "\n",
      "Model Performance metrics:\n",
      "**************************************************\n",
      "Accuracy: 0.7122\n",
      "Precision: 0.7285\n",
      "Recall: 0.7122\n",
      "F1 Score: 0.7069\n"
     ]
    }
   ],
   "source": [
    "display_model_performance(actual_sent=sentiments, predicted_sent=pred_sentiment, \n",
    "                                  classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in Progres......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_sentiment_sentiwordnet_lexicon(review,verbose=False):\n",
    "\n",
    "    # tokenize and POS tag text tokens\n",
    "    #tagged_text = [(token.text, token.tag_) for token in tn.nlp(review)]\n",
    "    tokens = nltk.word_tokenize (review)\n",
    "    tagged_text = [token.strip() for token in tokens]\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
    "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
    "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
    "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
    "        # if senti-synset is found        \n",
    "        if ss_set:\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # aggregate final scores\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score) / token_count, 2)\n",
    "    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
    "    if verbose:\n",
    "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
    "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
    "        # to display results in a nice table\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score, \n",
    "                                         norm_neg_score, norm_final_score]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                             ['Predicted Sentiment', 'Objectivity',\n",
    "                                                              'Positive', 'Negative', 'Overall']], \n",
    "                                                             labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "        \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: Utter dreck. I got to the 16 minute/27 second point, and gave up. I'd have given it a negative number review if that were possible (although 'pissible' is a more fitting word...). Unlike the sizzle you could see and practically feel between MacMurray and Stanwyck in the original, the chemistry between dumb ol' Dicky Crenna and whats-her-face here is just non-existent. The anklet becomes an unattractive chunky bracelet? There's no ciggy-lighting-by-fingertip? And I thought I'd be SICK when they have a mortified-looking (and rightly so, believe you me) Lee J. Cobb as Keyes practically burping/upchucking his way through the explanation of his \"Little Man\" to Mr. Garloupis. No offence to the non-sighted, but it looks as though a posse of blind men ran amuck with the set design of both the Dietrichson and Neff houses. The same goes for those horrid plaid pants that Phyllis wears. And crikey, how much $$ does Neff make, that he lives overlooking a huge marina? This, folks, again, all takes place in the first 16 and a half minutes. If you can get through more of it, you have a much stronger constitution than me, or you are a masochist. But please, take some Alka-Seltzer first, or you WILL develop a \"little man\" of your own that may never go away. Proceed with caution, obviously.\n",
      "Actual Sentiment: negative\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-35cff435629f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'REVIEW:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Actual Sentiment:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyze_sentiment_sentiwordnet_lexicon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-3977c1bc4045>\u001b[0m in \u001b[0;36manalyze_sentiment_sentiwordnet_lexicon\u001b[1;34m(review, verbose)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# get wordnet synsets based on POS tags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# get sentiment scores if synsets are found\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtagged_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mss_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'NN'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mswn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msenti_synsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(reviews[sample_id], sentiments[sample_id]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)    \n",
    "    print('*'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
